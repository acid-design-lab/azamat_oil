{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Архитектуры нейронок для рахных задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Координаты X, Y, TVD1 и TVD2 лежат отдельными листами в .xlsx файле\n",
    "# 2. Файлов .tfrecord не пугаться, в деталях коммита на всякий указал как открывать такие. \n",
    "# Там 4 таких файла уже в порядке следования дат, для нефти, воды, пластового и забойного.\n",
    "# Каждый тензор размерности [121,6,6]. \n",
    "# 3. Чтобы узнать какой дате соответствует индекс в тензоре, можно заюзать файл Dates_processed.csv.\n",
    "# Загружаете как датафрейм и запрашиваете по индексу строки, получаете дату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, LSTM, TimeDistributed, Input, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# specify your directory where files are located \n",
    "# tensors loading\n",
    "\n",
    "files_dir = '../data/processed/'\n",
    "loaded_tensors = dict()\n",
    "for file in [x for x in os.listdir(files_dir) if x.endswith(\"tfrecord\")]:\n",
    "    serialized_tensor = tf.io.read_file(os.path.join(files_dir,file))\n",
    "    loaded_tensors[file] = tf.io.parse_tensor(serialized_tensor, out_type=tf.float32)\n",
    "\n",
    "# coordinates loading \n",
    "df_coords = pd.read_excel(os.path.join(files_dir,\"Coordinates_processed.xlsx\"),sheet_name=['X','Y','TVD1','TVD2'],header=None)\n",
    "df_X_Y = pd.DataFrame({col: list(zip(df_coords[\"X\"][col], df_coords[\"Y\"][col])) for col in  df_coords[\"X\"].columns})\n",
    "df_TVD = pd.DataFrame({col: list(zip(df_coords[\"TVD1\"][col], df_coords[\"TVD2\"][col])) for col in  df_coords[\"TVD1\"].columns})\n",
    "\n",
    "# time loading \n",
    "time_sequence = pd.read_csv(os.path.join(files_dir,\"Dates_processed.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Параметры\n",
    "total_time_steps = 121  # Общее количество временных точек\n",
    "train_time_steps = 84   # Количество временных точек для обучения (до 2027 года)\n",
    "test_time_steps = total_time_steps - train_time_steps  # Количество временных точек для тестирования\n",
    "\n",
    "map_height = 6    # Высота карты (матрицы)\n",
    "map_width = 6     # Ширина карты (матрицы)\n",
    "batch_size = 1    # Размер пакета\n",
    "\n",
    "# Входы для обучающей модели\n",
    "input_oil_train = Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil')\n",
    "input_water_train = Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water')\n",
    "input_reservoir_pressure_train = Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure')\n",
    "input_bottomhole_pressure_train = Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure')\n",
    "\n",
    "# Входы для тестовой модели\n",
    "input_oil_test = Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil')\n",
    "input_water_test = Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water')\n",
    "input_reservoir_pressure_test = Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure')\n",
    "input_bottomhole_pressure_test = Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure')\n",
    "\n",
    "# CNN для каждого вида данных\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(input_tensor)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu'))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Модель для обучения\n",
    "cnn_oil_train = create_cnn(input_oil_train)\n",
    "cnn_water_train = create_cnn(input_water_train)\n",
    "cnn_reservoir_pressure_train = create_cnn(input_reservoir_pressure_train)\n",
    "cnn_bottomhole_pressure_train = create_cnn(input_bottomhole_pressure_train)\n",
    "\n",
    "merged_cnn_train = Concatenate(axis=-1)([cnn_oil_train, cnn_water_train, cnn_reservoir_pressure_train, cnn_bottomhole_pressure_train])\n",
    "lstm_out_train = LSTM(128, return_sequences=False)(merged_cnn_train)\n",
    "output_train = Dense(1, activation='linear', name='output')(lstm_out_train)\n",
    "\n",
    "model_train = Model(inputs=[input_oil_train, input_water_train, input_reservoir_pressure_train, input_bottomhole_pressure_train], outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Модель для тестирования\n",
    "cnn_oil_test = create_cnn(input_oil_test)\n",
    "cnn_water_test = create_cnn(input_water_test)\n",
    "cnn_reservoir_pressure_test = create_cnn(input_reservoir_pressure_test)\n",
    "cnn_bottomhole_pressure_test = create_cnn(input_bottomhole_pressure_test)\n",
    "\n",
    "merged_cnn_test = Concatenate(axis=-1)([cnn_oil_test, cnn_water_test, cnn_reservoir_pressure_test, cnn_bottomhole_pressure_test])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(merged_cnn_test)\n",
    "output_test = Dense(1, activation='linear', name='output')(lstm_out_test)\n",
    "\n",
    "model_test = Model(inputs=[input_oil_test, input_water_test, input_reservoir_pressure_test, input_bottomhole_pressure_test], outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Загрузка данных из тензоров\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Проверка форм данных\n",
    "print(\"Oil data shape:\", oil_data.shape)\n",
    "print(\"Water data shape:\", water_data.shape)\n",
    "print(\"Reservoir pressure data shape:\", reservoir_pressure_data.shape)\n",
    "print(\"Bottomhole pressure data shape:\", bottomhole_pressure_data.shape)\n",
    "\n",
    "# Убедимся, что формы данных совпадают с ожидаемой формой\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "oil_train = oil_data[:, :train_time_steps, :, :, :]\n",
    "water_train = water_data[:, :train_time_steps, :, :, :]\n",
    "reservoir_pressure_train = reservoir_pressure_data[:, :train_time_steps, :, :, :]\n",
    "bottomhole_pressure_train = bottomhole_pressure_data[:, :train_time_steps, :, :, :]\n",
    "\n",
    "oil_test = oil_data[:, train_time_steps:, :, :, :]\n",
    "water_test = water_data[:, train_time_steps:, :, :, :]\n",
    "reservoir_pressure_test = reservoir_pressure_data[:, train_time_steps:, :, :, :]\n",
    "bottomhole_pressure_test = bottomhole_pressure_data[:, train_time_steps:, :, :, :]\n",
    "\n",
    "# Дебит нефти для обучения и тестирования\n",
    "output_train = oil_data[:, :train_time_steps, map_height//2, map_width//2, 0].reshape((batch_size, train_time_steps, 1))\n",
    "output_test = oil_data[:, train_time_steps:, map_height//2, map_width//2, 0].reshape((batch_size, test_time_steps, 1))\n",
    "\n",
    "# Обучение модели\n",
    "model_train.fit([oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train], output_train, epochs=10)\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "model_test.evaluate([oil_test, water_test, reservoir_pressure_test, bottomhole_pressure_test], output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}