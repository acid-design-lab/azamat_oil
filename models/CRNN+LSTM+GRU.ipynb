{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Архитектуры нейронок для рахных задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Координаты X, Y, TVD1 и TVD2 лежат отдельными листами в .xlsx файле\n",
    "# 2. Файлов .tfrecord не пугаться, в деталях коммита на всякий указал как открывать такие. \n",
    "# Там 4 таких файла уже в порядке следования дат, для нефти, воды, пластового и забойного.\n",
    "# Каждый тензор размерности [121,6,6]. \n",
    "# 3. Чтобы узнать какой дате соответствует индекс в тензоре, можно заюзать файл Dates_processed.csv.\n",
    "# Загружаете как датафрейм и запрашиваете по индексу строки, получаете дату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, LSTM, TimeDistributed, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# specify your directory where files are located \n",
    "# tensors loading\n",
    "\n",
    "files_dir = '../data/processed/'\n",
    "loaded_tensors = dict()\n",
    "for file in [x for x in os.listdir(files_dir) if x.endswith(\"tfrecord\")]:\n",
    "    serialized_tensor = tf.io.read_file(os.path.join(files_dir,file))\n",
    "    loaded_tensors[file] = tf.io.parse_tensor(serialized_tensor, out_type=tf.float32)\n",
    "\n",
    "# coordinates loading \n",
    "df_coords = pd.read_excel(os.path.join(files_dir,\"Coordinates_processed.xlsx\"),sheet_name=['X','Y','TVD1','TVD2'],header=None)\n",
    "df_X_Y = pd.DataFrame({col: list(zip(df_coords[\"X\"][col], df_coords[\"Y\"][col])) for col in  df_coords[\"X\"].columns})\n",
    "df_TVD = pd.DataFrame({col: list(zip(df_coords[\"TVD1\"][col], df_coords[\"TVD2\"][col])) for col in  df_coords[\"TVD1\"].columns})\n",
    "\n",
    "# time loading \n",
    "time_sequence = pd.read_csv(os.path.join(files_dir,\"Dates_processed.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датасета для сплита 8/4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(N, W, P, Z, TVD1, TVD2, X, Y):\n",
    "  input_data = []\n",
    "  for i in range(len(W)):\n",
    "    combined_input = tf.concat([tf.reshape(W[i], [-1]), tf.reshape(P[i], [-1]), tf.reshape(Z[i], [-1])], axis=0)\n",
    "    input_data.append(combined_input)\n",
    "  return tf.stack(input_data), N\n",
    "\n",
    "input_data, target_data = prepare_data(N, W, P, Z, TVD1, TVD2, X, Y)\n",
    "\n",
    "constant_input = tf.concat([tf.reshape(TVD1, [-1]), tf.reshape(TVD2, [-1]),\n",
    "                            tf.reshape(X, [-1]), tf.reshape(Y, [-1])], axis=0)\n",
    "constant_input = tf.expand_dims(constant_input, axis=0)\n",
    "\n",
    "def generate_train_val_sets(input_data, target_data):\n",
    "  train_inputs = []\n",
    "  train_targets = []\n",
    "  val_inputs = []\n",
    "  val_targets = []\n",
    "\n",
    "  i = 1\n",
    "  while i + 12 <= len(input_data):\n",
    "    train_inputs.append(input_data[i:i+8])\n",
    "    train_targets.append(target_data[i+1:i+9])\n",
    "    val_inputs.append(input_data[i+8:i+12])\n",
    "    val_targets.append(target_data[i+9:i+13])\n",
    "    i += 12\n",
    "\n",
    "  return (tf.concat(train_inputs, axis=0), tf.concat(train_targets, axis=0),\n",
    "          tf.concat(val_inputs, axis=0), tf.concat(val_targets, axis=0))\n",
    "\n",
    "train_input, train_target, val_input, val_target = generate_train_val_sets(input_data, target_data)\n",
    "\n",
    "train_input = tf.reshape(train_input, (train_input.shape[0], 1, -1))\n",
    "val_input = tf.reshape(val_input, (val_input.shape[0], 1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Увеличение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# # Creating a date range from December 1, 2020, to December 1, 2030 with monthly frequency\n",
    "# monthly_range = pd.date_range(start='2020-12-01', end='2030-12-01', freq='MS')\n",
    "\n",
    "# # Function to generate 5 evenly distributed days in each month\n",
    "# def generate_evenly_distributed_days(monthly_dates):\n",
    "#     extended_dates = []\n",
    "#     for date in monthly_dates:\n",
    "#         month_end = date + MonthEnd(1)\n",
    "#         dates_in_month = pd.date_range(start=date, end=month_end, periods=5)\n",
    "#         extended_dates.extend(dates_in_month)\n",
    "#     return pd.to_datetime(extended_dates)\n",
    "\n",
    "# # Applying the function to generate the desired dates\n",
    "# evenly_distributed_dates = generate_evenly_distributed_days(monthly_range)\n",
    "\n",
    "# # Creating a DataFrame to display\n",
    "# evenly_distributed_date_df = pd.DataFrame(evenly_distributed_dates, columns=['Date'])\n",
    "\n",
    "# # Remove the time part from the dates\n",
    "# evenly_distributed_date_df['Date'] = evenly_distributed_date_df['Date'].dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление приемистости "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_dir = '../data/'\n",
    "df_injectivity = pd.read_excel(os.path.join(raw_data_dir,\"raw_data.xlsx\"),sheet_name=['приемистость'])\n",
    "df_injectivity = df_injectivity[\"приемистость\"].drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Пример кода преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initial matrix values\n",
    "matrix_values = [\n",
    "    ['p22', 'p23', 'p24', 'p30', 'p31', 'p32'],\n",
    "    ['p20', 'INJE3', 'p21', 'p28', 'INJE4', 'p29'],\n",
    "    ['p17', 'p18', 'p19', 'p25', 'p26', 'p27'],\n",
    "    ['p6', 'p7', 'p8', 'p14', 'p15', 'p16'],\n",
    "    ['p4', 'INJE1', 'p5', 'p12', 'INJE2', 'p13'],\n",
    "    ['p1', 'p2', 'p3', 'p9', 'p10', 'p11']\n",
    "]\n",
    "\n",
    "# Convert to numpy array and repeat\n",
    "matrix_array = np.array(matrix_values)\n",
    "repeated_matrix = np.tile(matrix_array, (121, 1, 1))\n",
    "\n",
    "# Create a mask to remove the specific elements\n",
    "mask = np.ones(repeated_matrix.shape, dtype=bool)\n",
    "mask[:, 1, 1] = False\n",
    "mask[:, 1, 4] = False\n",
    "mask[:, 4, 1] = False\n",
    "mask[:, 4, 4] = False  # This seems to be a repeat; ensure this element is removed\n",
    "\n",
    "# Apply the mask and reshape the array\n",
    "filtered_array = repeated_matrix[mask].reshape(121, 4, 8)\n",
    "\n",
    "# Display the shape to verify\n",
    "print(filtered_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Преобразование массивов (121,6,6) в (121,4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "oil_data = loaded_tensors['debit_neft_series.tfrecord'].numpy()\n",
    "water_data = loaded_tensors['debit_water_series.tfrecord'].numpy()\n",
    "reservoir_pressure_data = loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy()\n",
    "bottomhole_pressure_data = loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy()\n",
    "\n",
    "# Create a mask to remove the specific elements\n",
    "mask = np.ones(oil_data.shape, dtype=bool)\n",
    "mask[:, 1, 1] = False\n",
    "mask[:, 1, 4] = False\n",
    "mask[:, 4, 1] = False\n",
    "mask[:, 4, 4] = False  # This seems to be a repeat; ensure this element is removed\n",
    "\n",
    "# Apply the mask and reshape the array\n",
    "oil_data = oil_data[mask].reshape(121, 4, 8)\n",
    "water_data = water_data[mask].reshape(121, 4, 8)\n",
    "reservoir_pressure_data = reservoir_pressure_data[mask].reshape(121, 4, 8)\n",
    "bottomhole_pressure_data = bottomhole_pressure_data[mask].reshape(121, 4, 8)\n",
    "\n",
    "# reshape coords and TVD\n",
    "df_X_Y = df_X_Y.values[mask[0]].reshape(4, 8)\n",
    "df_TVD = df_TVD.values[mask[0]].reshape(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Преобразование массивов (121,6,6) в (121,4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "oil_data = loaded_tensors['debit_neft_series.tfrecord'].numpy()\n",
    "water_data = loaded_tensors['debit_water_series.tfrecord'].numpy()\n",
    "reservoir_pressure_data = loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy()\n",
    "bottomhole_pressure_data = loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy()\n",
    "\n",
    "# Create a mask to remove the specific elements\n",
    "mask = np.ones(oil_data.shape, dtype=bool)\n",
    "mask[:, 1, 1] = False\n",
    "mask[:, 1, 4] = False\n",
    "mask[:, 4, 1] = False\n",
    "mask[:, 4, 4] = False  # This seems to be a repeat; ensure this element is removed\n",
    "\n",
    "# Apply the mask and reshape the array\n",
    "oil_data = oil_data[mask].reshape(121, 4, 8)\n",
    "water_data = water_data[mask].reshape(121, 4, 8)\n",
    "reservoir_pressure_data = reservoir_pressure_data[mask].reshape(121, 4, 8)\n",
    "bottomhole_pressure_data = bottomhole_pressure_data[mask].reshape(121, 4, 8)\n",
    "\n",
    "# reshape coords and TVD\n",
    "df_X_Y = df_X_Y.values[mask[0]].reshape(4, 8)\n",
    "df_TVD = df_TVD.values[mask[0]].reshape(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Преобразование массивов (121,6,6) в (121,4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "oil_data = loaded_tensors['debit_neft_series.tfrecord'].numpy()\n",
    "water_data = loaded_tensors['debit_water_series.tfrecord'].numpy()\n",
    "reservoir_pressure_data = loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy()\n",
    "bottomhole_pressure_data = loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy()\n",
    "\n",
    "# Create a mask to remove the specific elements\n",
    "mask = np.ones(oil_data.shape, dtype=bool)\n",
    "mask[:, 1, 1] = False\n",
    "mask[:, 1, 4] = False\n",
    "mask[:, 4, 1] = False\n",
    "mask[:, 4, 4] = False  # This seems to be a repeat; ensure this element is removed\n",
    "\n",
    "# Apply the mask and reshape the array\n",
    "oil_data = oil_data[mask].reshape(121, 4, 8)\n",
    "water_data = water_data[mask].reshape(121, 4, 8)\n",
    "reservoir_pressure_data = reservoir_pressure_data[mask].reshape(121, 4, 8)\n",
    "bottomhole_pressure_data = bottomhole_pressure_data[mask].reshape(121, 4, 8)\n",
    "\n",
    "# reshape coords and TVD\n",
    "df_X_Y = df_X_Y.values[mask[0]].reshape(4, 8)\n",
    "df_TVD = df_TVD.values[mask[0]].reshape(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "total_time_steps = 121\n",
    "train_time_steps = 84\n",
    "test_time_steps = total_time_steps - train_time_steps\n",
    "map_height = 6\n",
    "map_width = 6\n",
    "batch_size = 1\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Function to create CNN layers for input tensors\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_tensor)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Input tensors for training model\n",
    "inputs_train = {\n",
    "    'oil': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(train_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Input tensors for testing model\n",
    "inputs_test = {\n",
    "    'oil': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(test_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Creating CNN layers for training and testing\n",
    "cnn_train = {name: create_cnn(tensor) for name, tensor in inputs_train.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "cnn_test = {name: create_cnn(tensor) for name, tensor in inputs_test.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for training\n",
    "flattened_coordinates_train = Flatten()(inputs_train['coordinates'])\n",
    "repeated_coordinates_train = RepeatVector(train_time_steps)(flattened_coordinates_train)\n",
    "flattened_tvd_train = Flatten()(inputs_train['tvd'])\n",
    "repeated_tvd_train = RepeatVector(train_time_steps)(flattened_tvd_train)\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for testing\n",
    "flattened_coordinates_test = Flatten()(inputs_test['coordinates'])\n",
    "repeated_coordinates_test = RepeatVector(test_time_steps)(flattened_coordinates_test)\n",
    "flattened_tvd_test = Flatten()(inputs_test['tvd'])\n",
    "repeated_tvd_test = RepeatVector(test_time_steps)(flattened_tvd_test)\n",
    "\n",
    "# Concatenating all inputs for training, including injectivity\n",
    "merged_train = Concatenate(axis=-1)(list(cnn_train.values()))\n",
    "flattened_merged_train = TimeDistributed(Flatten())(merged_train)\n",
    "combined_train = Concatenate(axis=-1)([flattened_merged_train, repeated_coordinates_train, repeated_tvd_train, inputs_train['injectivity']])\n",
    "# Example of adding more layers to the LSTM model\n",
    "lstm_out_train = LSTM(128, return_sequences=True)(combined_train)\n",
    "lstm_out_train = LSTM(64, return_sequences=False)(lstm_out_train)\n",
    "dropout_train = Dropout(dropout_rate)(lstm_out_train)\n",
    "dense_1_train = Dense(128, activation='relu')(dropout_train)\n",
    "dropout_train_2 = Dropout(dropout_rate)(dense_1_train)\n",
    "dense_2_train = Dense(72, activation='relu')(dropout_train_2)\n",
    "output_train = Dense(map_height * map_width, activation='linear', name='output')(dense_2_train)\n",
    "output_train = Reshape((map_height, map_width))(output_train)\n",
    "\n",
    "# Training model\n",
    "model_train = Model(inputs=list(inputs_train.values()), outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Concatenating all inputs for testing, including injectivity\n",
    "merged_test = Concatenate(axis=-1)(list(cnn_test.values()))\n",
    "flattened_merged_test = TimeDistributed(Flatten())(merged_test)\n",
    "combined_test = Concatenate(axis=-1)([flattened_merged_test, repeated_coordinates_test, repeated_tvd_test, inputs_test['injectivity']])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(combined_test)\n",
    "dropout_test = Dropout(dropout_rate)(lstm_out_test)\n",
    "dense_1_test = Dense(128, activation='relu')(dropout_test)\n",
    "dropout_test_2 = Dropout(dropout_rate)(dense_1_test)\n",
    "dense_2_test = Dense(72, activation='relu')(dropout_test_2)\n",
    "output_test = Dense(map_height * map_width, activation='linear', name='output')(dense_2_test)\n",
    "output_test = Reshape((map_height, map_width))(output_test)\n",
    "\n",
    "# Testing model\n",
    "model_test = Model(inputs=list(inputs_test.values()), outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Load and preprocess data (Assuming loaded_tensors and injectivity_array are already defined)\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Transforming df_X_Y and df_TVD to numpy arrays of required shape\n",
    "coordinates_data = np.array(df_X_Y.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "tvd_data = np.array(df_TVD.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "\n",
    "# Ensuring data shapes match expected shape\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Проверка на наличие пропусков и заполнение нулями или средними значениями\n",
    "oil_data = np.nan_to_num(oil_data)\n",
    "water_data = np.nan_to_num(water_data)\n",
    "reservoir_pressure_data = np.nan_to_num(reservoir_pressure_data)\n",
    "bottomhole_pressure_data = np.nan_to_num(bottomhole_pressure_data)\n",
    "injectivity_data = np.nan_to_num(injectivity_array.reshape((batch_size, total_time_steps, 4)))\n",
    "\n",
    "# Масштабирование данных\n",
    "scalers = {}\n",
    "for data_name, data in zip(['oil', 'water', 'reservoir_pressure', 'bottomhole_pressure', 'injectivity'],\n",
    "                           [oil_data, water_data, reservoir_pressure_data, bottomhole_pressure_data, injectivity_data]):\n",
    "    scalers[data_name] = MinMaxScaler()\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "    scaled_data = scalers[data_name].fit_transform(data_reshaped)\n",
    "    data[:] = scaled_data.reshape(data.shape)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "oil_train, oil_test = oil_data[:, :train_time_steps], oil_data[:, train_time_steps:]\n",
    "water_train, water_test = water_data[:, :train_time_steps], water_data[:, train_time_steps:]\n",
    "reservoir_pressure_train, reservoir_pressure_test = reservoir_pressure_data[:, :train_time_steps], reservoir_pressure_data[:, train_time_steps:]\n",
    "bottomhole_pressure_train, bottomhole_pressure_test = bottomhole_pressure_data[:, :train_time_steps], bottomhole_pressure_data[:, train_time_steps:]\n",
    "\n",
    "# Splitting injectivity data into training and test sets\n",
    "injectivity_train, injectivity_test = injectivity_data[:, :train_time_steps], injectivity_data[:, train_time_steps:]\n",
    "\n",
    "# Define output for training and testing\n",
    "output_train_data = oil_data[:, :train_time_steps, :, :, 0].reshape((batch_size, train_time_steps, map_height, map_width))\n",
    "output_test_data = oil_data[:, train_time_steps:, :, :, 0].reshape((batch_size, test_time_steps, map_height, map_width))\n",
    "\n",
    "# Adding EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Training the model with validation\n",
    "history = model_train.fit(\n",
    "    [oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train, coordinates_data, tvd_data, injectivity_train],\n",
    "    output_train_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "oil_data = loaded_tensors['debit_neft_series.tfrecord'].numpy()\n",
    "water_data = loaded_tensors['debit_water_series.tfrecord'].numpy()\n",
    "reservoir_pressure_data = loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy()\n",
    "bottomhole_pressure_data = loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy()\n",
    "\n",
    "# Create a mask to remove the specific elements\n",
    "mask = np.ones(oil_data.shape, dtype=bool)\n",
    "mask[:, 1, 1] = False\n",
    "mask[:, 1, 4] = False\n",
    "mask[:, 4, 1] = False\n",
    "mask[:, 4, 4] = False  # This seems to be a repeat; ensure this element is removed\n",
    "\n",
    "# Apply the mask and reshape the array\n",
    "oil_data = oil_data[mask].reshape(121, 4, 8)\n",
    "water_data = water_data[mask].reshape(121, 4, 8)\n",
    "reservoir_pressure_data = reservoir_pressure_data[mask].reshape(121, 4, 8)\n",
    "bottomhole_pressure_data = bottomhole_pressure_data[mask].reshape(121, 4, 8)\n",
    "\n",
    "# reshape coords and TVD\n",
    "df_X_Y = df_X_Y.values[mask[0]].reshape(4, 8)\n",
    "df_TVD = df_TVD.values[mask[0]].reshape(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "total_time_steps = 121\n",
    "train_time_steps = 84\n",
    "test_time_steps = total_time_steps - train_time_steps\n",
    "map_height = 6\n",
    "map_width = 6\n",
    "batch_size = 1\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Function to create CNN layers for input tensors\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_tensor)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Input tensors for training model\n",
    "inputs_train = {\n",
    "    'oil': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(train_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Input tensors for testing model\n",
    "inputs_test = {\n",
    "    'oil': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(test_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Creating CNN layers for training and testing\n",
    "cnn_train = {name: create_cnn(tensor) for name, tensor in inputs_train.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "cnn_test = {name: create_cnn(tensor) for name, tensor in inputs_test.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for training\n",
    "flattened_coordinates_train = Flatten()(inputs_train['coordinates'])\n",
    "repeated_coordinates_train = RepeatVector(train_time_steps)(flattened_coordinates_train)\n",
    "flattened_tvd_train = Flatten()(inputs_train['tvd'])\n",
    "repeated_tvd_train = RepeatVector(train_time_steps)(flattened_tvd_train)\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for testing\n",
    "flattened_coordinates_test = Flatten()(inputs_test['coordinates'])\n",
    "repeated_coordinates_test = RepeatVector(test_time_steps)(flattened_coordinates_test)\n",
    "flattened_tvd_test = Flatten()(inputs_test['tvd'])\n",
    "repeated_tvd_test = RepeatVector(test_time_steps)(flattened_tvd_test)\n",
    "\n",
    "# Concatenating all inputs for training, including injectivity\n",
    "merged_train = Concatenate(axis=-1)(list(cnn_train.values()))\n",
    "flattened_merged_train = TimeDistributed(Flatten())(merged_train)\n",
    "combined_train = Concatenate(axis=-1)([flattened_merged_train, repeated_coordinates_train, repeated_tvd_train, inputs_train['injectivity']])\n",
    "# Example of adding more layers to the LSTM model\n",
    "lstm_out_train = LSTM(128, return_sequences=True)(combined_train)\n",
    "lstm_out_train = LSTM(64, return_sequences=False)(lstm_out_train)\n",
    "dropout_train = Dropout(dropout_rate)(lstm_out_train)\n",
    "dense_1_train = Dense(128, activation='relu')(dropout_train)\n",
    "dropout_train_2 = Dropout(dropout_rate)(dense_1_train)\n",
    "dense_2_train = Dense(72, activation='relu')(dropout_train_2)\n",
    "output_train = Dense(map_height * map_width, activation='linear', name='output')(dense_2_train)\n",
    "output_train = Reshape((map_height, map_width))(output_train)\n",
    "\n",
    "# Training model\n",
    "model_train = Model(inputs=list(inputs_train.values()), outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Concatenating all inputs for testing, including injectivity\n",
    "merged_test = Concatenate(axis=-1)(list(cnn_test.values()))\n",
    "flattened_merged_test = TimeDistributed(Flatten())(merged_test)\n",
    "combined_test = Concatenate(axis=-1)([flattened_merged_test, repeated_coordinates_test, repeated_tvd_test, inputs_test['injectivity']])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(combined_test)\n",
    "dropout_test = Dropout(dropout_rate)(lstm_out_test)\n",
    "dense_1_test = Dense(128, activation='relu')(dropout_test)\n",
    "dropout_test_2 = Dropout(dropout_rate)(dense_1_test)\n",
    "dense_2_test = Dense(72, activation='relu')(dropout_test_2)\n",
    "output_test = Dense(map_height * map_width, activation='linear', name='output')(dense_2_test)\n",
    "output_test = Reshape((map_height, map_width))(output_test)\n",
    "\n",
    "# Testing model\n",
    "model_test = Model(inputs=list(inputs_test.values()), outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Load and preprocess data (Assuming loaded_tensors and injectivity_array are already defined)\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Transforming df_X_Y and df_TVD to numpy arrays of required shape\n",
    "coordinates_data = np.array(df_X_Y.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "tvd_data = np.array(df_TVD.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "\n",
    "# Ensuring data shapes match expected shape\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Проверка на наличие пропусков и заполнение нулями или средними значениями\n",
    "oil_data = np.nan_to_num(oil_data)\n",
    "water_data = np.nan_to_num(water_data)\n",
    "reservoir_pressure_data = np.nan_to_num(reservoir_pressure_data)\n",
    "bottomhole_pressure_data = np.nan_to_num(bottomhole_pressure_data)\n",
    "injectivity_data = np.nan_to_num(injectivity_array.reshape((batch_size, total_time_steps, 4)))\n",
    "\n",
    "# Масштабирование данных\n",
    "scalers = {}\n",
    "for data_name, data in zip(['oil', 'water', 'reservoir_pressure', 'bottomhole_pressure', 'injectivity'],\n",
    "                           [oil_data, water_data, reservoir_pressure_data, bottomhole_pressure_data, injectivity_data]):\n",
    "    scalers[data_name] = MinMaxScaler()\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "    scaled_data = scalers[data_name].fit_transform(data_reshaped)\n",
    "    data[:] = scaled_data.reshape(data.shape)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "oil_train, oil_test = oil_data[:, :train_time_steps], oil_data[:, train_time_steps:]\n",
    "water_train, water_test = water_data[:, :train_time_steps], water_data[:, train_time_steps:]\n",
    "reservoir_pressure_train, reservoir_pressure_test = reservoir_pressure_data[:, :train_time_steps], reservoir_pressure_data[:, train_time_steps:]\n",
    "bottomhole_pressure_train, bottomhole_pressure_test = bottomhole_pressure_data[:, :train_time_steps], bottomhole_pressure_data[:, train_time_steps:]\n",
    "\n",
    "# Splitting injectivity data into training and test sets\n",
    "injectivity_train, injectivity_test = injectivity_data[:, :train_time_steps], injectivity_data[:, train_time_steps:]\n",
    "\n",
    "# Define output for training and testing\n",
    "output_train_data = oil_data[:, :train_time_steps, :, :, 0].reshape((batch_size, train_time_steps, map_height, map_width))\n",
    "output_test_data = oil_data[:, train_time_steps:, :, :, 0].reshape((batch_size, test_time_steps, map_height, map_width))\n",
    "\n",
    "# Adding EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Training the model with validation\n",
    "history = model_train.fit(\n",
    "    [oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train, coordinates_data, tvd_data, injectivity_train],\n",
    "    output_train_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "total_time_steps = 121\n",
    "train_time_steps = 84\n",
    "test_time_steps = total_time_steps - train_time_steps\n",
    "map_height = 6\n",
    "map_width = 6\n",
    "batch_size = 1\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Function to create CNN layers for input tensors\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_tensor)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Input tensors for training model\n",
    "inputs_train = {\n",
    "    'oil': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(train_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Input tensors for testing model\n",
    "inputs_test = {\n",
    "    'oil': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(test_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Creating CNN layers for training and testing\n",
    "cnn_train = {name: create_cnn(tensor) for name, tensor in inputs_train.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "cnn_test = {name: create_cnn(tensor) for name, tensor in inputs_test.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for training\n",
    "flattened_coordinates_train = Flatten()(inputs_train['coordinates'])\n",
    "repeated_coordinates_train = RepeatVector(train_time_steps)(flattened_coordinates_train)\n",
    "flattened_tvd_train = Flatten()(inputs_train['tvd'])\n",
    "repeated_tvd_train = RepeatVector(train_time_steps)(flattened_tvd_train)\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for testing\n",
    "flattened_coordinates_test = Flatten()(inputs_test['coordinates'])\n",
    "repeated_coordinates_test = RepeatVector(test_time_steps)(flattened_coordinates_test)\n",
    "flattened_tvd_test = Flatten()(inputs_test['tvd'])\n",
    "repeated_tvd_test = RepeatVector(test_time_steps)(flattened_tvd_test)\n",
    "\n",
    "# Concatenating all inputs for training, including injectivity\n",
    "merged_train = Concatenate(axis=-1)(list(cnn_train.values()))\n",
    "flattened_merged_train = TimeDistributed(Flatten())(merged_train)\n",
    "combined_train = Concatenate(axis=-1)([flattened_merged_train, repeated_coordinates_train, repeated_tvd_train, inputs_train['injectivity']])\n",
    "# Example of adding more layers to the LSTM model\n",
    "lstm_out_train = LSTM(128, return_sequences=True)(combined_train)\n",
    "lstm_out_train = LSTM(64, return_sequences=False)(lstm_out_train)\n",
    "dropout_train = Dropout(dropout_rate)(lstm_out_train)\n",
    "dense_1_train = Dense(128, activation='relu')(dropout_train)\n",
    "dropout_train_2 = Dropout(dropout_rate)(dense_1_train)\n",
    "dense_2_train = Dense(72, activation='relu')(dropout_train_2)\n",
    "output_train = Dense(map_height * map_width, activation='linear', name='output')(dense_2_train)\n",
    "output_train = Reshape((map_height, map_width))(output_train)\n",
    "\n",
    "# Training model\n",
    "model_train = Model(inputs=list(inputs_train.values()), outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Concatenating all inputs for testing, including injectivity\n",
    "merged_test = Concatenate(axis=-1)(list(cnn_test.values()))\n",
    "flattened_merged_test = TimeDistributed(Flatten())(merged_test)\n",
    "combined_test = Concatenate(axis=-1)([flattened_merged_test, repeated_coordinates_test, repeated_tvd_test, inputs_test['injectivity']])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(combined_test)\n",
    "dropout_test = Dropout(dropout_rate)(lstm_out_test)\n",
    "dense_1_test = Dense(128, activation='relu')(dropout_test)\n",
    "dropout_test_2 = Dropout(dropout_rate)(dense_1_test)\n",
    "dense_2_test = Dense(72, activation='relu')(dropout_test_2)\n",
    "output_test = Dense(map_height * map_width, activation='linear', name='output')(dense_2_test)\n",
    "output_test = Reshape((map_height, map_width))(output_test)\n",
    "\n",
    "# Testing model\n",
    "model_test = Model(inputs=list(inputs_test.values()), outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Load and preprocess data (Assuming loaded_tensors and injectivity_array are already defined)\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Transforming df_X_Y and df_TVD to numpy arrays of required shape\n",
    "coordinates_data = np.array(df_X_Y.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "tvd_data = np.array(df_TVD.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "\n",
    "# Ensuring data shapes match expected shape\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Проверка на наличие пропусков и заполнение нулями или средними значениями\n",
    "oil_data = np.nan_to_num(oil_data)\n",
    "water_data = np.nan_to_num(water_data)\n",
    "reservoir_pressure_data = np.nan_to_num(reservoir_pressure_data)\n",
    "bottomhole_pressure_data = np.nan_to_num(bottomhole_pressure_data)\n",
    "injectivity_data = np.nan_to_num(injectivity_array.reshape((batch_size, total_time_steps, 4)))\n",
    "\n",
    "# Масштабирование данных\n",
    "scalers = {}\n",
    "for data_name, data in zip(['oil', 'water', 'reservoir_pressure', 'bottomhole_pressure', 'injectivity'],\n",
    "                           [oil_data, water_data, reservoir_pressure_data, bottomhole_pressure_data, injectivity_data]):\n",
    "    scalers[data_name] = MinMaxScaler()\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "    scaled_data = scalers[data_name].fit_transform(data_reshaped)\n",
    "    data[:] = scaled_data.reshape(data.shape)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "oil_train, oil_test = oil_data[:, :train_time_steps], oil_data[:, train_time_steps:]\n",
    "water_train, water_test = water_data[:, :train_time_steps], water_data[:, train_time_steps:]\n",
    "reservoir_pressure_train, reservoir_pressure_test = reservoir_pressure_data[:, :train_time_steps], reservoir_pressure_data[:, train_time_steps:]\n",
    "bottomhole_pressure_train, bottomhole_pressure_test = bottomhole_pressure_data[:, :train_time_steps], bottomhole_pressure_data[:, train_time_steps:]\n",
    "\n",
    "# Splitting injectivity data into training and test sets\n",
    "injectivity_train, injectivity_test = injectivity_data[:, :train_time_steps], injectivity_data[:, train_time_steps:]\n",
    "\n",
    "# Define output for training and testing\n",
    "output_train_data = oil_data[:, :train_time_steps, :, :, 0].reshape((batch_size, train_time_steps, map_height, map_width))\n",
    "output_test_data = oil_data[:, train_time_steps:, :, :, 0].reshape((batch_size, test_time_steps, map_height, map_width))\n",
    "\n",
    "# Adding EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Training the model with validation\n",
    "history = model_train.fit(\n",
    "    [oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train, coordinates_data, tvd_data, injectivity_train],\n",
    "    output_train_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "total_time_steps = 121\n",
    "train_time_steps = 84\n",
    "test_time_steps = total_time_steps - train_time_steps\n",
    "map_height = 6\n",
    "map_width = 6\n",
    "batch_size = 1\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Function to create CNN layers for input tensors\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_tensor)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Input tensors for training model\n",
    "inputs_train = {\n",
    "    'oil': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(train_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Input tensors for testing model\n",
    "inputs_test = {\n",
    "    'oil': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(test_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Creating CNN layers for training and testing\n",
    "cnn_train = {name: create_cnn(tensor) for name, tensor in inputs_train.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "cnn_test = {name: create_cnn(tensor) for name, tensor in inputs_test.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for training\n",
    "flattened_coordinates_train = Flatten()(inputs_train['coordinates'])\n",
    "repeated_coordinates_train = RepeatVector(train_time_steps)(flattened_coordinates_train)\n",
    "flattened_tvd_train = Flatten()(inputs_train['tvd'])\n",
    "repeated_tvd_train = RepeatVector(train_time_steps)(flattened_tvd_train)\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for testing\n",
    "flattened_coordinates_test = Flatten()(inputs_test['coordinates'])\n",
    "repeated_coordinates_test = RepeatVector(test_time_steps)(flattened_coordinates_test)\n",
    "flattened_tvd_test = Flatten()(inputs_test['tvd'])\n",
    "repeated_tvd_test = RepeatVector(test_time_steps)(flattened_tvd_test)\n",
    "\n",
    "# Concatenating all inputs for training, including injectivity\n",
    "merged_train = Concatenate(axis=-1)(list(cnn_train.values()))\n",
    "flattened_merged_train = TimeDistributed(Flatten())(merged_train)\n",
    "combined_train = Concatenate(axis=-1)([flattened_merged_train, repeated_coordinates_train, repeated_tvd_train, inputs_train['injectivity']])\n",
    "# Example of adding more layers to the LSTM model\n",
    "lstm_out_train = LSTM(128, return_sequences=True)(combined_train)\n",
    "lstm_out_train = LSTM(64, return_sequences=False)(lstm_out_train)\n",
    "dropout_train = Dropout(dropout_rate)(lstm_out_train)\n",
    "dense_1_train = Dense(128, activation='relu')(dropout_train)\n",
    "dropout_train_2 = Dropout(dropout_rate)(dense_1_train)\n",
    "dense_2_train = Dense(72, activation='relu')(dropout_train_2)\n",
    "output_train = Dense(map_height * map_width, activation='linear', name='output')(dense_2_train)\n",
    "output_train = Reshape((map_height, map_width))(output_train)\n",
    "\n",
    "# Training model\n",
    "model_train = Model(inputs=list(inputs_train.values()), outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Concatenating all inputs for testing, including injectivity\n",
    "merged_test = Concatenate(axis=-1)(list(cnn_test.values()))\n",
    "flattened_merged_test = TimeDistributed(Flatten())(merged_test)\n",
    "combined_test = Concatenate(axis=-1)([flattened_merged_test, repeated_coordinates_test, repeated_tvd_test, inputs_test['injectivity']])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(combined_test)\n",
    "dropout_test = Dropout(dropout_rate)(lstm_out_test)\n",
    "dense_1_test = Dense(128, activation='relu')(dropout_test)\n",
    "dropout_test_2 = Dropout(dropout_rate)(dense_1_test)\n",
    "dense_2_test = Dense(72, activation='relu')(dropout_test_2)\n",
    "output_test = Dense(map_height * map_width, activation='linear', name='output')(dense_2_test)\n",
    "output_test = Reshape((map_height, map_width))(output_test)\n",
    "\n",
    "# Testing model\n",
    "model_test = Model(inputs=list(inputs_test.values()), outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Load and preprocess data (Assuming loaded_tensors and injectivity_array are already defined)\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Transforming df_X_Y and df_TVD to numpy arrays of required shape\n",
    "coordinates_data = np.array(df_X_Y.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "tvd_data = np.array(df_TVD.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "\n",
    "# Ensuring data shapes match expected shape\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Проверка на наличие пропусков и заполнение нулями или средними значениями\n",
    "oil_data = np.nan_to_num(oil_data)\n",
    "water_data = np.nan_to_num(water_data)\n",
    "reservoir_pressure_data = np.nan_to_num(reservoir_pressure_data)\n",
    "bottomhole_pressure_data = np.nan_to_num(bottomhole_pressure_data)\n",
    "injectivity_data = np.nan_to_num(injectivity_array.reshape((batch_size, total_time_steps, 4)))\n",
    "\n",
    "# Масштабирование данных\n",
    "scalers = {}\n",
    "for data_name, data in zip(['oil', 'water', 'reservoir_pressure', 'bottomhole_pressure', 'injectivity'],\n",
    "                           [oil_data, water_data, reservoir_pressure_data, bottomhole_pressure_data, injectivity_data]):\n",
    "    scalers[data_name] = MinMaxScaler()\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "    scaled_data = scalers[data_name].fit_transform(data_reshaped)\n",
    "    data[:] = scaled_data.reshape(data.shape)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "oil_train, oil_test = oil_data[:, :train_time_steps], oil_data[:, train_time_steps:]\n",
    "water_train, water_test = water_data[:, :train_time_steps], water_data[:, train_time_steps:]\n",
    "reservoir_pressure_train, reservoir_pressure_test = reservoir_pressure_data[:, :train_time_steps], reservoir_pressure_data[:, train_time_steps:]\n",
    "bottomhole_pressure_train, bottomhole_pressure_test = bottomhole_pressure_data[:, :train_time_steps], bottomhole_pressure_data[:, train_time_steps:]\n",
    "\n",
    "# Splitting injectivity data into training and test sets\n",
    "injectivity_train, injectivity_test = injectivity_data[:, :train_time_steps], injectivity_data[:, train_time_steps:]\n",
    "\n",
    "# Define output for training and testing\n",
    "output_train_data = oil_data[:, :train_time_steps, :, :, 0].reshape((batch_size, train_time_steps, map_height, map_width))\n",
    "output_test_data = oil_data[:, train_time_steps:, :, :, 0].reshape((batch_size, test_time_steps, map_height, map_width))\n",
    "\n",
    "# Adding EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Training the model with validation\n",
    "history = model_train.fit(\n",
    "    [oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train, coordinates_data, tvd_data, injectivity_train],\n",
    "    output_train_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, TimeDistributed, LSTM, Dense, Concatenate, RepeatVector, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "total_time_steps = 121\n",
    "train_time_steps = 84\n",
    "test_time_steps = total_time_steps - train_time_steps\n",
    "map_height = 6\n",
    "map_width = 6\n",
    "batch_size = 1\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Function to create CNN layers for input tensors\n",
    "def create_cnn(input_tensor):\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_tensor)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "\n",
    "# Input tensors for training model\n",
    "inputs_train = {\n",
    "    'oil': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(train_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(train_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Input tensors for testing model\n",
    "inputs_test = {\n",
    "    'oil': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_oil'),\n",
    "    'water': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_water'),\n",
    "    'reservoir_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_reservoir_pressure'),\n",
    "    'bottomhole_pressure': Input(shape=(test_time_steps, map_height, map_width, 1), name='input_bottomhole_pressure'),\n",
    "    'coordinates': Input(shape=(map_height, map_width, 2), name='input_coordinates'),\n",
    "    'tvd': Input(shape=(map_height, map_width, 2), name='input_tvd'),\n",
    "    'injectivity': Input(shape=(test_time_steps, 4), name='input_injectivity')  # добавляем приемистость\n",
    "}\n",
    "\n",
    "# Creating CNN layers for training and testing\n",
    "cnn_train = {name: create_cnn(tensor) for name, tensor in inputs_train.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "cnn_test = {name: create_cnn(tensor) for name, tensor in inputs_test.items() if name not in ['coordinates', 'tvd', 'injectivity']}\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for training\n",
    "flattened_coordinates_train = Flatten()(inputs_train['coordinates'])\n",
    "repeated_coordinates_train = RepeatVector(train_time_steps)(flattened_coordinates_train)\n",
    "flattened_tvd_train = Flatten()(inputs_train['tvd'])\n",
    "repeated_tvd_train = RepeatVector(train_time_steps)(flattened_tvd_train)\n",
    "\n",
    "# Flatten and repeat coordinates and TVD for testing\n",
    "flattened_coordinates_test = Flatten()(inputs_test['coordinates'])\n",
    "repeated_coordinates_test = RepeatVector(test_time_steps)(flattened_coordinates_test)\n",
    "flattened_tvd_test = Flatten()(inputs_test['tvd'])\n",
    "repeated_tvd_test = RepeatVector(test_time_steps)(flattened_tvd_test)\n",
    "\n",
    "# Concatenating all inputs for training, including injectivity\n",
    "merged_train = Concatenate(axis=-1)(list(cnn_train.values()))\n",
    "flattened_merged_train = TimeDistributed(Flatten())(merged_train)\n",
    "combined_train = Concatenate(axis=-1)([flattened_merged_train, repeated_coordinates_train, repeated_tvd_train, inputs_train['injectivity']])\n",
    "# Example of adding more layers to the LSTM model\n",
    "lstm_out_train = LSTM(128, return_sequences=True)(combined_train)\n",
    "lstm_out_train = LSTM(64, return_sequences=False)(lstm_out_train)\n",
    "dropout_train = Dropout(dropout_rate)(lstm_out_train)\n",
    "dense_1_train = Dense(128, activation='relu')(dropout_train)\n",
    "dropout_train_2 = Dropout(dropout_rate)(dense_1_train)\n",
    "dense_2_train = Dense(72, activation='relu')(dropout_train_2)\n",
    "output_train = Dense(map_height * map_width, activation='linear', name='output')(dense_2_train)\n",
    "output_train = Reshape((map_height, map_width))(output_train)\n",
    "\n",
    "# Training model\n",
    "model_train = Model(inputs=list(inputs_train.values()), outputs=output_train)\n",
    "model_train.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Concatenating all inputs for testing, including injectivity\n",
    "merged_test = Concatenate(axis=-1)(list(cnn_test.values()))\n",
    "flattened_merged_test = TimeDistributed(Flatten())(merged_test)\n",
    "combined_test = Concatenate(axis=-1)([flattened_merged_test, repeated_coordinates_test, repeated_tvd_test, inputs_test['injectivity']])\n",
    "lstm_out_test = LSTM(128, return_sequences=False)(combined_test)\n",
    "dropout_test = Dropout(dropout_rate)(lstm_out_test)\n",
    "dense_1_test = Dense(128, activation='relu')(dropout_test)\n",
    "dropout_test_2 = Dropout(dropout_rate)(dense_1_test)\n",
    "dense_2_test = Dense(72, activation='relu')(dropout_test_2)\n",
    "output_test = Dense(map_height * map_width, activation='linear', name='output')(dense_2_test)\n",
    "output_test = Reshape((map_height, map_width))(output_test)\n",
    "\n",
    "# Testing model\n",
    "model_test = Model(inputs=list(inputs_test.values()), outputs=output_test)\n",
    "model_test.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Load and preprocess data (Assuming loaded_tensors and injectivity_array are already defined)\n",
    "oil_data = np.expand_dims(loaded_tensors['debit_neft_series.tfrecord'].numpy(), axis=-1)\n",
    "water_data = np.expand_dims(loaded_tensors['debit_water_series.tfrecord'].numpy(), axis=-1)\n",
    "reservoir_pressure_data = np.expand_dims(loaded_tensors['debit_plast_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "bottomhole_pressure_data = np.expand_dims(loaded_tensors['debit_zaboy_pressure_series.tfrecord'].numpy(), axis=-1)\n",
    "\n",
    "# Transforming df_X_Y and df_TVD to numpy arrays of required shape\n",
    "coordinates_data = np.array(df_X_Y.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "tvd_data = np.array(df_TVD.applymap(lambda x: list(x)).values.tolist()).reshape((batch_size, map_height, map_width, 2))\n",
    "\n",
    "# Ensuring data shapes match expected shape\n",
    "oil_data = oil_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "water_data = water_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "reservoir_pressure_data = reservoir_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "bottomhole_pressure_data = bottomhole_pressure_data.reshape((batch_size, total_time_steps, map_height, map_width, 1))\n",
    "\n",
    "# Проверка на наличие пропусков и заполнение нулями или средними значениями\n",
    "oil_data = np.nan_to_num(oil_data)\n",
    "water_data = np.nan_to_num(water_data)\n",
    "reservoir_pressure_data = np.nan_to_num(reservoir_pressure_data)\n",
    "bottomhole_pressure_data = np.nan_to_num(bottomhole_pressure_data)\n",
    "injectivity_data = np.nan_to_num(injectivity_array.reshape((batch_size, total_time_steps, 4)))\n",
    "\n",
    "# Масштабирование данных\n",
    "scalers = {}\n",
    "for data_name, data in zip(['oil', 'water', 'reservoir_pressure', 'bottomhole_pressure', 'injectivity'],\n",
    "                           [oil_data, water_data, reservoir_pressure_data, bottomhole_pressure_data, injectivity_data]):\n",
    "    scalers[data_name] = MinMaxScaler()\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "    scaled_data = scalers[data_name].fit_transform(data_reshaped)\n",
    "    data[:] = scaled_data.reshape(data.shape)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "oil_train, oil_test = oil_data[:, :train_time_steps], oil_data[:, train_time_steps:]\n",
    "water_train, water_test = water_data[:, :train_time_steps], water_data[:, train_time_steps:]\n",
    "reservoir_pressure_train, reservoir_pressure_test = reservoir_pressure_data[:, :train_time_steps], reservoir_pressure_data[:, train_time_steps:]\n",
    "bottomhole_pressure_train, bottomhole_pressure_test = bottomhole_pressure_data[:, :train_time_steps], bottomhole_pressure_data[:, train_time_steps:]\n",
    "\n",
    "# Splitting injectivity data into training and test sets\n",
    "injectivity_train, injectivity_test = injectivity_data[:, :train_time_steps], injectivity_data[:, train_time_steps:]\n",
    "\n",
    "# Define output for training and testing\n",
    "output_train_data = oil_data[:, :train_time_steps, :, :, 0].reshape((batch_size, train_time_steps, map_height, map_width))\n",
    "output_test_data = oil_data[:, train_time_steps:, :, :, 0].reshape((batch_size, test_time_steps, map_height, map_width))\n",
    "\n",
    "# Adding EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Training the model with validation\n",
    "history = model_train.fit(\n",
    "    [oil_train, water_train, reservoir_pressure_train, bottomhole_pressure_train, coordinates_data, tvd_data, injectivity_train],\n",
    "    output_train_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(val_target, val_output):\n",
    "  val_target = val_target.numpy()\n",
    "  val_output = val_output.numpy()\n",
    "\n",
    "  output_shape = val_target.shape[1:]\n",
    "\n",
    "  fig, axes = plt.subplots(output_shape[0], output_shape[1], figsize=(20, 20))\n",
    "  fig.suptitle('Model Performance on Validation Time Steps', fontsize=16)\n",
    "\n",
    "  time_steps = np.arange(val_output.shape[0])\n",
    "\n",
    "  for i in range(output_shape[0]):\n",
    "    for j in range(output_shape[1]):\n",
    "      ax = axes[i, j]\n",
    "      real_values = val_target[:, i, j]\n",
    "      predicted_values = val_output[:, i, j]\n",
    "\n",
    "      ax.plot(time_steps, real_values, label='Real', color='blue')\n",
    "      ax.plot(time_steps, predicted_values, label='Predicted', color='red')\n",
    "      ax.set_title(f'Value at ({i}, {j})')\n",
    "      ax.set_ylim(-10, 160)\n",
    "      ax.legend()\n",
    "\n",
    "  plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "  plt.show()\n",
    "\n",
    "plot_model_performance(val_target, val_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}